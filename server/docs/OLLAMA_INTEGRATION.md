# Ollama é›†æˆè¯´æ˜

æœ¬é¡¹ç›®ä½¿ç”¨ Ollama æä¾› AI ç®€å†è¯„åˆ†åŠŸèƒ½ï¼ŒåŸºäº `deepseek-r1:7b` æ¨¡å‹è¿›è¡Œ JD ä¸ç®€å†çš„æ™ºèƒ½åŒ¹é…åˆ†æã€‚

## æ¶æ„è¯´æ˜

### æœåŠ¡ç»„ä»¶

1. **Ollama æœåŠ¡** (`ollama` å®¹å™¨)
   - è¿è¡Œ Ollama æœåŠ¡å™¨
   - ç«¯å£ï¼š11434
   - æ¨¡å‹ï¼šdeepseek-r1:7b
   - è‡ªåŠ¨ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹

2. **Backend æœåŠ¡** (`backend` å®¹å™¨)
   - è°ƒç”¨ Ollama API è¿›è¡Œç®€å†åˆ†æ
   - é€šè¿‡ Docker ç½‘ç»œè®¿é—® Ollamaï¼š`http://ollama:11434/v1`

3. **ç½‘ç»œ**
   - æ‰€æœ‰æœåŠ¡åœ¨ `readysethire-network` ç½‘ç»œä¸­
   - æœåŠ¡é—´é€šè¿‡å®¹å™¨åç§°é€šä¿¡

## ç¯å¢ƒå˜é‡

### `.env.dev` / `.env.production`

```bash
# Ollama é…ç½®
OLLAMA_BASE_URL=http://ollama:11434/v1
OLLAMA_MODEL=deepseek-r1:7b
```

## API ç«¯ç‚¹

### åˆ†æ JD å’Œç®€å†åŒ¹é…åº¦

**POST** `/api/resume-rating/analyze`

**æƒé™ï¼š** ADMIN æˆ– EMPLOYEE

**è¯·æ±‚ä½“ï¼š**
```json
{
  "jdText": "å²—ä½æè¿°æ–‡æœ¬...",
  "resumeText": "ç®€å†æ–‡æœ¬...",
  "settings": {
    "level": "Mid",
    "mustHaveWeight": 60,
    "language": "ä¸­æ–‡",
    "anonymize": true
  }
}
```

**å“åº”ï¼š**
```json
{
  "success": true,
  "data": {
    "score": 78,
    "conclusion": "HIRE",
    "topStrengths": [
      {
        "point": "5å¹´ä»¥ä¸ŠReactå¼€å‘ç»éªŒ",
        "evidence": "å€™é€‰äººåœ¨ç®€å†ä¸­æ˜ç¡®æåˆ°..."
      }
    ],
    "topGaps": [
      {
        "gap": "ç¼ºå°‘äº‘åŸç”ŸæŠ€æœ¯ç»éªŒ",
        "severity": "high"
      }
    ],
    "risks": ["ç®€å†æè¿°è¿‡äºç¬¼ç»Ÿ"],
    "hardRequirements": [...],
    "skillsMatrix": [...],
    "interviewQuestions": [...]
  }
}
```

## éƒ¨ç½²æŒ‡å—

### 1. æœ¬åœ°å¼€å‘ç¯å¢ƒ

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
cd server
docker compose up -d

# æŸ¥çœ‹ Ollama æ—¥å¿—ï¼Œç¡®è®¤æ¨¡å‹å·²ä¸‹è½½
docker logs ollama

# æµ‹è¯• Ollama æ˜¯å¦æ­£å¸¸
curl http://localhost:11434/api/tags
```

### 2. ç”Ÿäº§ç¯å¢ƒ

ç¡®ä¿ `.env.production` é…ç½®æ­£ç¡®ï¼Œç„¶åï¼š

```bash
# å¯åŠ¨æœåŠ¡
docker compose -f docker-compose.yml up -d

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker compose ps

# æŸ¥çœ‹æ—¥å¿—
docker compose logs -f backend ollama
```

## æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šæ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡

**ç—‡çŠ¶ï¼š**
```
Error: æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡ã€‚è¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œã€‚
```

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥ Ollama å®¹å™¨æ˜¯å¦è¿è¡Œï¼š
   ```bash
   docker ps | grep ollama
   ```

2. æ£€æŸ¥ Ollama æ—¥å¿—ï¼š
   ```bash
   docker logs ollama
   ```

3. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼š
   ```bash
   docker exec backend ping ollama
   ```

### é—®é¢˜ï¼šæ¨¡å‹æœªä¸‹è½½

**ç—‡çŠ¶ï¼š**
```
Error: model not found
```

**è§£å†³æ–¹æ¡ˆï¼š**
1. è¿›å…¥ Ollama å®¹å™¨æ‰‹åŠ¨ä¸‹è½½ï¼š
   ```bash
   docker exec -it ollama ollama pull deepseek-r1:7b
   ```

2. æ£€æŸ¥å·²ä¸‹è½½çš„æ¨¡å‹ï¼š
   ```bash
   docker exec -it ollama ollama list
   ```

### é—®é¢˜ï¼šåˆ†æè¶…æ—¶

**ç—‡çŠ¶ï¼š**
```
Error: Request timeout
```

**è§£å†³æ–¹æ¡ˆï¼š**
1. deepseek-r1:7b æ¨¡å‹è¾ƒå¤§ï¼Œé¦–æ¬¡æ¨ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
2. ç¡®ä¿æœåŠ¡å™¨æœ‰è¶³å¤Ÿçš„å†…å­˜ï¼ˆå»ºè®®è‡³å°‘ 8GBï¼‰
3. å¯ä»¥è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚ `deepseek-r1:1.5b`ï¼‰

## æ€§èƒ½ä¼˜åŒ–

### 1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹

ä¿®æ”¹ `.env` æ–‡ä»¶ï¼š
```bash
OLLAMA_MODEL=deepseek-r1:1.5b
```

ç„¶åé‡æ–°å¯åŠ¨æœåŠ¡ï¼š
```bash
docker compose down
docker compose up -d
```

### 2. è°ƒæ•´ Docker èµ„æºé™åˆ¶

åœ¨ `docker-compose.yml` ä¸­æ·»åŠ èµ„æºé™åˆ¶ï¼š
```yaml
ollama:
  deploy:
    resources:
      limits:
        memory: 8G
      reservations:
        memory: 4G
```

### 3. å¯ç”¨ GPU åŠ é€Ÿ

å¦‚æœæœåŠ¡å™¨æœ‰ GPUï¼š
```yaml
ollama:
  image: ollama/ollama
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
```

## ç›‘æ§å’Œæ—¥å¿—

### æŸ¥çœ‹å®æ—¶æ—¥å¿—

```bash
# Backend æ—¥å¿—
docker logs -f backend

# Ollama æ—¥å¿—
docker logs -f ollama
```

### æ—¥å¿—å…³é”®ä¿¡æ¯

**æˆåŠŸçš„åˆ†æè¯·æ±‚ï¼š**
```
ğŸ” Analyzing resume against JD...
ğŸ“¤ Sending request to Ollama...
âœ… Received response from Ollama in 3500ms
âœ… Analysis completed successfully
```

**å¤±è´¥çš„è¯·æ±‚ï¼š**
```
âŒ Failed to analyze resume: ...
```

## æ›´æ¢æ¨¡å‹

å¦‚æœéœ€è¦ä½¿ç”¨å…¶ä»–æ¨¡å‹ï¼ˆå¦‚ OpenAIã€Anthropicï¼‰ï¼š

1. ä¿®æ”¹ `src/services/ollama.ts`
2. æ›´æ–°ç¯å¢ƒå˜é‡
3. è°ƒæ•´ Prompt æ ¼å¼
4. é‡æ–°æ„å»ºå’Œéƒ¨ç½²

## æœ€ä½³å®è·µ

1. **å®šæœŸæ¸…ç†æ—¥å¿—**
   ```bash
   docker compose logs --tail=100 ollama > ollama.log
   ```

2. **ç›‘æ§èµ„æºä½¿ç”¨**
   ```bash
   docker stats ollama backend
   ```

3. **å¤‡ä»½æ¨¡å‹æ•°æ®**
   ```bash
   docker cp ollama:/root/.ollama ./ollama-backup
   ```

4. **æµ‹è¯•æ–°æ¨¡å‹**
   åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å‰ï¼Œå…ˆåœ¨å¼€å‘ç¯å¢ƒæµ‹è¯•æ–°æ¨¡å‹çš„æ•ˆæœ

## ç›¸å…³èµ„æº

- [Ollama å®˜æ–¹æ–‡æ¡£](https://github.com/ollama/ollama)
- [DeepSeek æ¨¡å‹](https://huggingface.co/deepseek-ai)
- [OpenAI SDK for Node.js](https://github.com/openai/openai-node)
